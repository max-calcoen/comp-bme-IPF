{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07d08828-39be-453d-9c15-7d0737ceb72f",
      "metadata": {},
      "source": [
        "## Module_2:\n",
        "\n",
        "## Team Members:\n",
        "Max Calcoen, Jack O'Hearn\n",
        "\n",
        "## Project Title: TBD\n",
        "*(Fill in)*\n",
        "\n",
        "idea: how do blood vessel summary statistics differ across left and superior lobes?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8372d796-186a-4ae2-9b4f-0065979e555a",
      "metadata": {},
      "source": [
        "## Project Goal: TBD\n",
        "This project seeks to... *(what is the purpose of your project -- i.e., describe the question that you seek to answer by analyzing data.)*\n",
        "\n",
        "\n",
        "idea: this project seeks to find out how the blood vessels of left and superior lobes differ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "91408b75-185a-4d66-9ce7-7c7aabbde5e1",
      "metadata": {},
      "source": [
        "## Disease Background: \n",
        "*Fill in information and please note that this module is truncated and only has 5 bullets (instead of the 11 that you did for Module #1).*\n",
        "\n",
        "* Prevalence & incidence ([source](https://pmc.ncbi.nlm.nih.gov/articles/PMC6313500/))\n",
        "    - north america / europe: ~2.8 to 9.3 per 100,000 person-years (varies by definition)\n",
        "    - usa, narrow definition: ~6.8 per 100,000; broader: up to ~16.3–17.4 per 100,000\n",
        "    - prevalence in u.s. estimated ~10 to 60 cases / 100,000 (rare disease threshold)\n",
        "* Risk factors (genetic, lifestyle) ([source](https://pmc.ncbi.nlm.nih.gov/articles/PMC6777743/))\n",
        "    - older age / aging (disease primarily presents in middle to older adults)\n",
        "    - male sex bias\n",
        "    - cigarette smoking / smoking history (strongest environmental risk)\n",
        "    - genetic predispositions: mutations in telomerase genes, surfactant genes, shorter telomeres, MUC5B promoter variant (minor allele)\n",
        "    - microbiome / microbial burden in lung (higher bacterial load in BAL, certain genera like Streptococcus, Staphylococcus)\n",
        "    - comorbidities / cofactors: gastroesophageal reflux disease (GERD), environmental exposures (metal dusts, silica, wood dust), viral injury, lung injury agents\n",
        "* Symptoms ([source](https://www.ncbi.nlm.nih.gov/books/NBK448162/))\n",
        "    - gradual onset progressive (shortness of breath) on exertion\n",
        "    - dry nonproductive chronic cough\n",
        "    -  bibasilar “velcro” crackles on auscultation (fine inspiratory crackles)\n",
        "    - reduced exercise tolerance, fatigue, weight loss (constitutional)\n",
        "    - pulmonary function test: restrictive pattern, decreased forced vital capacity (FVC), decreased DLCO (diffusing capacity)\n",
        "* Standard of care treatment(s) ([source](https://pmc.ncbi.nlm.nih.gov/articles/PMC6111543/))\n",
        "    - antifibrotic therapy: Pirfenidone (slows decline in lung function, reduces fibrosis mediators)\n",
        "    - antifibrotic therapy: Nintedanib (tyrosine kinase inhibitor, slows FVC decline)\n",
        "    - supportive therapies: supplemental oxygen, pulmonary rehabilitation, symptom control (cough management)\n",
        "    - management of comorbidities (GERD, pulmonary hypertension)\n",
        "    - lung transplantation\n",
        "    - clinical trials / emerging therapies (targeting profibrotic pathways, biomarkers)\n",
        "* Biological mechanisms (anatomy, organ physiology, cell & molecular physiology) ([source](https://pmc.ncbi.nlm.nih.gov/articles/PMC2675823/))\n",
        "    - impaired epithelial regeneration / aberrant repair, with persistent activation of epithelial cells and failed re-epithelialization\n",
        "    - senescence, mitochondrial dysfunction, oxidative stress in epithelial cells leading to pro-fibrotic signaling\n",
        "    - release of profibrotic mediators (TGF-β, connective tissue growth factor, PDGF, fibronectin, integrins) from injured epithelium & mesenchymal cells\n",
        "    - recruitment, activation and differentiation of fibroblasts → myofibroblasts → excessive ECM (extracellular matrix) deposition (collagen, fibronectin, proteoglycans)\n",
        "    - mechanical stress feedback: matrix stiffening, mechanotransduction, latent TGF-ß activation via contraction of myofibroblasts\n",
        "    - cross talk with immune cells / inflammation: dysregulated wound healing, low grade chronic inflammation, altered macrophage / fibrocyte responses\n",
        "    - epigenetic alterations, noncoding RNAs, altered gene expression networks in fibrotic lung cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b99aefb-cb03-4bd8-b972-437eb0e02dfe",
      "metadata": {},
      "source": [
        "## Data-Set: \n",
        "*(Describe the data set(s) you will analyze. Cite the source(s) of the data. Describe how the data was collected -- What techniques were used? What units are the data measured in? Etc.)*",
        "- The dataset is composed of Unpublished data collected by the Peirce-Cottler Lab (Dept. of Biomedical Engineering) and Kim Lab (Division of Pulmonary and Critical Care) at the University of Virginia School of Medicine.",
        "- the dataset is composed of 78 black and white images (.jpg), collected at various depths of a fibrotic mouse lung.",
        "- White in the images symbolizes fibrotic lesion, and black symbolizes healthy lung tissue.",
        "- The images come from a Bleomycin-induced Lung Injury Model, where an antibiotic primarily used as chemotherapy (but also causes lung fibrosis) is administered to a mouse.",
        "- 3 weeks later, the mice were harvested.",
        "- The mouse lung tissue is then fixed, mounted, and sliced, then fluorescent microscopy was performed.",
        "- The mouse lungs were immunostained for 3 proteins of interest:",
        "   - desmin (myofibroblasts)",
        "   - smooth muscle alpha actin (large blood vessel smooth muscle cells)",
        "   - CD-31 (endothelial cells)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cde622-5508-4a54-aba8-77b454138bff",
      "metadata": {},
      "source": [
        "## Data Analyis: \n",
        "*(Describe how you analyzed the data. This is where you should intersperse your Python code so that anyone reading this can run your code to perform the analysis that you did, generate your figures, etc.)*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c884d2ef",
      "metadata": {},
      "source": [
        "### data folder setup (for running code below)\n",
        "```html\n",
        "/data\n",
        "    /imaging\n",
        "        MASK_Sk658 Llobe ch010017.jpg\n",
        "        ...here contains all the images\n",
        "    depths.csv\n",
        "    Filenames and Depths (old).csv\n",
        "    pct_white_pixels.csv\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81c9c9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"FILE: get_pct_white.ipynb\"\"\"\n",
        "\n",
        "# %%\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from termcolor import colored\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images = pd.DataFrame()\n",
        "\n",
        "data_path = r\"data\"\n",
        "imaging_path = r\"imaging\"\n",
        "filenames = os.listdir(os.path.join(data_path, imaging_path))\n",
        "depths = pd.read_csv(os.path.join(data_path, \"depths.csv\"))\n",
        "\n",
        "for i in filenames:\n",
        "    img = cv2.imread(os.path.join(data_path, imaging_path, i), 0)\n",
        "    try:\n",
        "        depth = depths[depths[\"Filenames\"].str.lower() == i.lower()][\n",
        "            \"Depth from lung surface (in micrometers) where image was acquired\"\n",
        "        ].values[0]\n",
        "        # some files are named with SK658 and some with Sk658\n",
        "    except IndexError:\n",
        "        print(f\"couldn't find depth for file {i}\")\n",
        "        continue\n",
        "    images = pd.concat(\n",
        "        [images, pd.DataFrame([{\"filename\": i, \"image\": img, \"depth\": depth}])],\n",
        "        ignore_index=True,\n",
        "    )\n",
        "display(images.head())\n",
        "\n",
        "# %%\n",
        "white_counts = []\n",
        "black_counts = []\n",
        "white_percents = []\n",
        "\n",
        "\n",
        "for x in range(len(images)):\n",
        "    _, binary = cv2.threshold(images.iloc[x][\"image\"], 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    white = np.sum(binary == 255)\n",
        "    black = np.sum(binary == 0)\n",
        "\n",
        "    white_counts.append(white)\n",
        "    black_counts.append(black)\n",
        "\n",
        "# print the number of white and black pixels in each image.\n",
        "\n",
        "print(colored(\"Counts of pixel by color in each image\", \"yellow\"))\n",
        "for x in range(len(images)):\n",
        "    print(colored(f\"White pixels in image {x}: {white_counts[x]}\", \"white\"))\n",
        "    print(colored(f\"Black pixels in image {x}: {black_counts[x]}\", \"black\"))\n",
        "    print()\n",
        "\n",
        "# calculate the percentage of pixels in each image that are white and make a list that contains these percentages for each filename\n",
        "\n",
        "for x in range(len(images)):\n",
        "    white_percent = 100 * (white_counts[x] / (black_counts[x] + white_counts[x]))\n",
        "    white_percents.append(white_percent)\n",
        "\n",
        "# print the filename (on one line in red font), and below that line print the percent white pixels and depth\n",
        "\n",
        "print(colored(\"Percent white px:\", \"yellow\"))\n",
        "for x in range(len(images)):\n",
        "    print(colored(f\"{images.iloc[x]['filename']}:\", \"red\"))\n",
        "    print(f\"{white_percents[x]}% White | Depth: {images.iloc[x]['depth']} microns\")\n",
        "    print()\n",
        "\n",
        "# %%\n",
        "\"\"\"Write your data to a .csv file\"\"\"\n",
        "\n",
        "# Create a DataFrame that includes the filenames, depths, and percentage of white pixels\n",
        "df = pd.DataFrame(\n",
        "    {\"filename\": images[\"filename\"], \"depth\": images[\"depth\"], \"white_percent\": white_percents}\n",
        ")\n",
        "\n",
        "# Write that DataFrame to a .csv file\n",
        "\n",
        "df.to_csv(os.path.join(data_path, \"pct_white_pixels.csv\"), index=False)\n",
        "\n",
        "# %%\n",
        "# display graph\n",
        "plt.scatter(images[\"depth\"], white_percents, marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
        "plt.title(\"Plot of depth of image vs percentage white pixels\")\n",
        "plt.xlabel(\"depth of image\")\n",
        "plt.ylabel(\"white pixels as a percentage of total pixels\")\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b636be8",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"FILE: contour_detection.ipynb\"\"\"\n",
        "# %%\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images = pd.DataFrame()\n",
        "\n",
        "data_path = r\"data\"\n",
        "imaging_path = r\"imaging\"\n",
        "filenames = os.listdir(os.path.join(data_path, imaging_path))\n",
        "depths = pd.read_csv(os.path.join(data_path, \"depths.csv\"))\n",
        "\n",
        "# display(filenames)\n",
        "for i in filenames:\n",
        "    img = cv2.imread(os.path.join(data_path, imaging_path, i), 0)\n",
        "    try:\n",
        "        depth = depths[depths[\"Filenames\"].str.lower() == i.lower()][\n",
        "            \"Depth from lung surface (in micrometers) where image was acquired\"\n",
        "        ].values[0]\n",
        "        # some files are named with SK658 and some with Sk658\n",
        "    except IndexError:\n",
        "        print(f\"couldn't find depth for file {i}\")\n",
        "        continue\n",
        "    images = pd.concat(\n",
        "        [images, pd.DataFrame([{\"filename\": i, \"image\": img, \"depth\": depth}])],\n",
        "        ignore_index=True,\n",
        "    )\n",
        "\n",
        "print(images.shape)\n",
        "\n",
        "# %%\n",
        "print(images[\"filename\"])\n",
        "\n",
        "# %%\n",
        "img = (\n",
        "    images[images[\"filename\"] == \"MASK_Sk658 Llobe ch010034.jpg\"][\"image\"]\n",
        "    .values[0]\n",
        "    .copy()\n",
        ")\n",
        "\n",
        "# convert to rgb instead of grayscale\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# remove small contours\n",
        "\n",
        "img_contour_simple = img.copy()\n",
        "\n",
        "contours, _ = cv2.findContours(\n",
        "    img_contour_simple, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        ")\n",
        "\n",
        "for cntr in contours:\n",
        "    if cv2.contourArea(cntr) > 1000:\n",
        "        continue\n",
        "    convHull = cv2.convexHull(cntr)\n",
        "    cv2.drawContours(\n",
        "        img_contour_simple, [convHull], -1, (0, 0, 0), thickness=cv2.FILLED\n",
        "    )\n",
        "img_contour_simple = cv2.cvtColor(img_contour_simple, cv2.COLOR_GRAY2RGB)\n",
        "plt.imshow(img_contour_simple)\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "img_dilate = img.copy()\n",
        "img_dilate = cv2.dilate(img_dilate, np.ones((15, 15), np.uint8), iterations=1)\n",
        "\n",
        "plt.imshow(img_dilate, cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# look at contours on dilated image\n",
        "img_dilated_contour = img_dilate.copy()\n",
        "contours, _ = cv2.findContours(\n",
        "    img_dilated_contour, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        ")\n",
        "\n",
        "for cntr in contours:\n",
        "    if cv2.contourArea(cntr) > 10000:\n",
        "        continue\n",
        "    convHull = cv2.convexHull(cntr)\n",
        "    cv2.drawContours(\n",
        "        img_dilated_contour, [convHull], -1, (0, 0, 0), thickness=cv2.FILLED\n",
        "    )\n",
        "img_dilated_contour = cv2.cvtColor(img_dilated_contour, cv2.COLOR_GRAY2RGB)\n",
        "plt.imshow(img_dilated_contour)\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# combine\n",
        "img_combine = img_contour_simple.copy()\n",
        "img_combine = cv2.dilate(img_combine, np.ones((15, 15), np.uint8), iterations=1)\n",
        "contours, _ = cv2.findContours(img_combine, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "for cntr in contours:\n",
        "    if cv2.contourArea(cntr) > 10000:\n",
        "        continue\n",
        "    convHull = cv2.convexHull(cntr)\n",
        "    cv2.drawContours(img_combine, [convHull], -1, (0, 0, 0), thickness=cv2.FILLED)\n",
        "img_combine = cv2.cvtColor(img_combine, cv2.COLOR_GRAY2RGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c67b6a4-ec94-4d28-b2a7-f6b860495118",
      "metadata": {},
      "source": [
        "## Verify and validate your analysis: \n",
        "*(Describe how you checked to see that your analysis gave you an answer that you believe (verify). Describe how your determined if your analysis gave you an answer that is supported by other evidence (e.g., a published paper).*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2736cf95-2b93-444f-90c8-d40a54fc1df1",
      "metadata": {},
      "source": [
        "## Conclusions and Ethical Implications: \n",
        "*(Think about the answer your analysis generated, draw conclusions related to your overarching question, and discuss the ethical implications of your conclusions.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f023b735-6efb-43ed-a03d-eb4a9cdb734e",
      "metadata": {},
      "source": [
        "## Limitations and Future Work: \n",
        "*(Think about the answer your analysis generated, draw conclusions related to your overarching question, and discuss the ethical implications of your conclusions.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9295960-2404-43dc-b46f-9a6f823f1657",
      "metadata": {},
      "source": [
        "## NOTES FROM YOUR TEAM: \n",
        "*This is where our team is taking notes and recording activity.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd725b7f-9741-46b6-a213-9518da9201c3",
      "metadata": {},
      "source": [
        "## QUESTIONS FOR YOUR TA: \n",
        "*These are questions we have for our TA.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
